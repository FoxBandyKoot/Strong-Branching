{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prédiction multi-noeud\n",
    "On fait ici un modèle de prédiction multi-noeud.\n",
    "On prends tous les noeuds fils en même temps, que l'on donne au modèle.\n",
    "\n",
    "La prédiction est une regression. La classification one-hot a été testée auparavant, mais n'a pas donné de résultats probants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parents: 27,873\n",
      "Wall time: 1min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import os\n",
    "\n",
    "import pylab\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sb_utils.read_data import get_trees\n",
    "\n",
    "path = 'data/second_samples/normalized/train/'\n",
    "trees = get_trees(path)\n",
    "total_len = sum([len(t) for t in trees.values()])\n",
    "print(f'Number of parents: {total_len:,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows:  27,371\n",
      "Number of features (childs): (5, 12)\n",
      "Number of features (parents): 13\n",
      "\n",
      "Number of training examples:  21,896\n",
      "Number of validation examples:  5,475\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def tree_to_dataset(tree, number_of_childs=5):\n",
    "    \"\"\"\n",
    "    Créer une ligne par parent.\n",
    "    Il est possible qu'un parent ait moins d'enfants qu'attendu.\n",
    "    Ils sont ignorés.\n",
    "    \"\"\"\n",
    "    parents, childs, values = [], [], []\n",
    "    \n",
    "    for parent_node in tree.values():\n",
    "        feature_names = sorted(parent_node.features.keys())\n",
    "        final_row = []\n",
    "        final_values = []\n",
    "        \n",
    "        if len(parent_node.children_nodes) != number_of_childs:\n",
    "            continue  # Invalid parent\n",
    "        \n",
    "        for child in parent_node.children_nodes:\n",
    "            child_row = np.array([child.features[f] for f in feature_names])\n",
    "            final_row.append(child_row)\n",
    "            final_values.append(child.value)\n",
    "        \n",
    "        childs.append(np.array(final_row))\n",
    "        values.append(np.array(final_values))\n",
    "        parents.append(np.array([parent_node.features[f] for f in feature_names]\n",
    "                                + [parent_node.value]))\n",
    "        \n",
    "    return np.array(parents), np.array(childs), np.array(values)\n",
    "\n",
    "def build_dataset(trees):\n",
    "    parents, childs, values = [], [], []\n",
    "    for tree in trees.values():\n",
    "        parents_t, childs_t, values_t = tree_to_dataset(tree)\n",
    "        if childs_t.shape[0] != 0:\n",
    "            childs.append(childs_t)\n",
    "            values.append(values_t)\n",
    "            parents.append(parents_t)\n",
    "    \n",
    "    parents = np.concatenate(parents, axis=0)\n",
    "    childs = np.concatenate(childs, axis=0)\n",
    "    values = np.concatenate(values, axis=0)\n",
    "    \n",
    "    return parents, childs, values\n",
    "\n",
    "parents, childs, values = build_dataset(trees)\n",
    "print(f'Number of rows: {childs.shape[0]: ,}')\n",
    "print(f'Number of features (childs): ({childs.shape[1]}, {childs.shape[2]})')\n",
    "print(f'Number of features (parents): {parents.shape[1]}\\n')\n",
    "\n",
    "X = [(p, c) for p, c in zip(parents, childs)]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, values, test_size=0.2)\n",
    "childs_train, childs_test = [x[1] for x in X_train], [x[1] for x in X_test]\n",
    "parents_train, parents_test = [x[0] for x in X_train], [x[0] for x in X_test]\n",
    "print(f'Number of training examples: {len(childs_train): ,}')\n",
    "print(f'Number of validation examples: {len(childs_test): ,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class Dataset(torch.utils.data.dataset.Dataset):\n",
    "    def __init__(self, parents, childs, values):\n",
    "        self.parents = torch.FloatTensor(parents)\n",
    "        self.childs = torch.FloatTensor(childs)\n",
    "        self.values = torch.tensor(values)\n",
    "        self.number_of_nodes = self.childs.shape[1]\n",
    "        self.n_features = self.childs.shape[1] * self.childs.shape[2] + self.parents.shape[1]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.childs)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        perm = torch.randperm(self.number_of_nodes)\n",
    "        row, values = self.childs[index][perm], self.values[index][perm]\n",
    "        row = row.view(-1)\n",
    "        row = torch.cat((row, self.parents[index]), axis=0)\n",
    "        return row, values\n",
    "\n",
    "train_dataset = Dataset(parents_train, childs_train, y_train)\n",
    "test_dataset = Dataset(parents_test, childs_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_dataset(model, criterion, dataloader):\n",
    "    model.eval()\n",
    "    losses = []\n",
    "    precisions = []\n",
    "    \n",
    "    cuda = torch.cuda.is_available()\n",
    "    if cuda:\n",
    "        model = model.cuda()\n",
    "        criterion = criterion.cuda()\n",
    "    \n",
    "    for rows, values in dataloader:\n",
    "        if cuda:\n",
    "            rows = rows.cuda()\n",
    "            values = values.cuda()\n",
    "\n",
    "        output = model(rows)\n",
    "        # o, v = -torch.log(output).float(), -torch.log(values).float()\n",
    "        o, v = output, values.float()\n",
    "        losses.append(criterion(o, v).item())\n",
    "        precisions.extend([\n",
    "            abs(output.item() - value.item())\n",
    "            for output, value in zip(o.view(-1), v.view(-1))\n",
    "        ])\n",
    "    \n",
    "    return sum(losses) / len(losses), np.mean(precisions), np.std(precisions)\n",
    "\n",
    "def train(model, data_train, data_val,\n",
    "          criterion, optimizer, epochs,\n",
    "          print_each=1):\n",
    "    train_loss, train_prec = [], []\n",
    "    val_loss, val_prec = [], []\n",
    "    \n",
    "    cuda = torch.cuda.is_available()\n",
    "    if cuda:\n",
    "        model = model.cuda()\n",
    "        criterion = criterion.cuda()\n",
    "    \n",
    "    for e in range(1, epochs+1):\n",
    "        model.train()\n",
    "        for rows, values in data_train:\n",
    "            if cuda:\n",
    "                rows = rows.cuda()\n",
    "                values = values.cuda()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            pred = model(rows)\n",
    "            values = values.float()\n",
    "\n",
    "            loss = criterion(pred, values)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        if e % print_each == 0:\n",
    "            loss, prec, std_prec_t = eval_dataset(model, criterion, data_train)\n",
    "            train_loss.append(loss)\n",
    "            train_prec.append(prec)\n",
    "\n",
    "            loss, prec, std_prec_v = eval_dataset(model, criterion, data_val)\n",
    "            val_loss.append(loss)\n",
    "            val_prec.append(prec)\n",
    "            \n",
    "            print(f'Epoch {e}')\n",
    "            print(f'Train loss: {train_loss[-1]:.5f} \\t\\t\\t\\t\\tVal loss: {val_loss[-1]:.5f}')\n",
    "            print(f'Train precision: {train_prec[-1]:.2e} ({std_prec_t:.2e})\\\n",
    "                  \\tVal precision: {val_prec[-1]:.2e} ({std_prec_v:.2e})')\n",
    "    \n",
    "    return train_loss, train_prec, val_loss, val_prec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, output_size, n_layers, n_hidden):\n",
    "        super(MLP, self).__init__()\n",
    "        \n",
    "        self.project = nn.Sequential(\n",
    "            nn.Linear(input_size, n_hidden),\n",
    "            nn.SELU(),\n",
    "        )\n",
    "        \n",
    "        self.resnet = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Linear(n_hidden, n_hidden // 2),\n",
    "                nn.BatchNorm1d(n_hidden // 2),\n",
    "                nn.SELU(),\n",
    "                nn.Linear(n_hidden // 2, n_hidden),\n",
    "                nn.BatchNorm1d(n_hidden),\n",
    "                nn.SELU(),\n",
    "            )\n",
    "            for _ in range(n_layers)\n",
    "        ])\n",
    "        \n",
    "        self.output = nn.Linear(n_hidden, output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.project(x)\n",
    "        for layer in self.resnet:\n",
    "            x = x + layer(x)\n",
    "        x = self.output(x)\n",
    "        return torch.sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "├─Sequential: 1-1                        [-1, 800]                 --\n",
      "|    └─Linear: 2-1                       [-1, 800]                 59,200\n",
      "|    └─SELU: 2-2                         [-1, 800]                 --\n",
      "├─ModuleList: 1                          []                        --\n",
      "|    └─Sequential: 2-3                   [-1, 800]                 --\n",
      "|    |    └─Linear: 3-1                  [-1, 400]                 320,400\n",
      "|    |    └─BatchNorm1d: 3-2             [-1, 400]                 800\n",
      "|    |    └─SELU: 3-3                    [-1, 400]                 --\n",
      "|    |    └─Linear: 3-4                  [-1, 800]                 320,800\n",
      "|    |    └─BatchNorm1d: 3-5             [-1, 800]                 1,600\n",
      "|    |    └─SELU: 3-6                    [-1, 800]                 --\n",
      "|    └─Sequential: 2-4                   [-1, 800]                 --\n",
      "|    |    └─Linear: 3-7                  [-1, 400]                 320,400\n",
      "|    |    └─BatchNorm1d: 3-8             [-1, 400]                 800\n",
      "|    |    └─SELU: 3-9                    [-1, 400]                 --\n",
      "|    |    └─Linear: 3-10                 [-1, 800]                 320,800\n",
      "|    |    └─BatchNorm1d: 3-11            [-1, 800]                 1,600\n",
      "|    |    └─SELU: 3-12                   [-1, 800]                 --\n",
      "|    └─Sequential: 2-5                   [-1, 800]                 --\n",
      "|    |    └─Linear: 3-13                 [-1, 400]                 320,400\n",
      "|    |    └─BatchNorm1d: 3-14            [-1, 400]                 800\n",
      "|    |    └─SELU: 3-15                   [-1, 400]                 --\n",
      "|    |    └─Linear: 3-16                 [-1, 800]                 320,800\n",
      "|    |    └─BatchNorm1d: 3-17            [-1, 800]                 1,600\n",
      "|    |    └─SELU: 3-18                   [-1, 800]                 --\n",
      "|    └─Sequential: 2-6                   [-1, 800]                 --\n",
      "|    |    └─Linear: 3-19                 [-1, 400]                 320,400\n",
      "|    |    └─BatchNorm1d: 3-20            [-1, 400]                 800\n",
      "|    |    └─SELU: 3-21                   [-1, 400]                 --\n",
      "|    |    └─Linear: 3-22                 [-1, 800]                 320,800\n",
      "|    |    └─BatchNorm1d: 3-23            [-1, 800]                 1,600\n",
      "|    |    └─SELU: 3-24                   [-1, 800]                 --\n",
      "|    └─Sequential: 2-7                   [-1, 800]                 --\n",
      "|    |    └─Linear: 3-25                 [-1, 400]                 320,400\n",
      "|    |    └─BatchNorm1d: 3-26            [-1, 400]                 800\n",
      "|    |    └─SELU: 3-27                   [-1, 400]                 --\n",
      "|    |    └─Linear: 3-28                 [-1, 800]                 320,800\n",
      "|    |    └─BatchNorm1d: 3-29            [-1, 800]                 1,600\n",
      "|    |    └─SELU: 3-30                   [-1, 800]                 --\n",
      "|    └─Sequential: 2-8                   [-1, 800]                 --\n",
      "|    |    └─Linear: 3-31                 [-1, 400]                 320,400\n",
      "|    |    └─BatchNorm1d: 3-32            [-1, 400]                 800\n",
      "|    |    └─SELU: 3-33                   [-1, 400]                 --\n",
      "|    |    └─Linear: 3-34                 [-1, 800]                 320,800\n",
      "|    |    └─BatchNorm1d: 3-35            [-1, 800]                 1,600\n",
      "|    |    └─SELU: 3-36                   [-1, 800]                 --\n",
      "|    └─Sequential: 2-9                   [-1, 800]                 --\n",
      "|    |    └─Linear: 3-37                 [-1, 400]                 320,400\n",
      "|    |    └─BatchNorm1d: 3-38            [-1, 400]                 800\n",
      "|    |    └─SELU: 3-39                   [-1, 400]                 --\n",
      "|    |    └─Linear: 3-40                 [-1, 800]                 320,800\n",
      "|    |    └─BatchNorm1d: 3-41            [-1, 800]                 1,600\n",
      "|    |    └─SELU: 3-42                   [-1, 800]                 --\n",
      "|    └─Sequential: 2-10                  [-1, 800]                 --\n",
      "|    |    └─Linear: 3-43                 [-1, 400]                 320,400\n",
      "|    |    └─BatchNorm1d: 3-44            [-1, 400]                 800\n",
      "|    |    └─SELU: 3-45                   [-1, 400]                 --\n",
      "|    |    └─Linear: 3-46                 [-1, 800]                 320,800\n",
      "|    |    └─BatchNorm1d: 3-47            [-1, 800]                 1,600\n",
      "|    |    └─SELU: 3-48                   [-1, 800]                 --\n",
      "|    └─Sequential: 2-11                  [-1, 800]                 --\n",
      "|    |    └─Linear: 3-49                 [-1, 400]                 320,400\n",
      "|    |    └─BatchNorm1d: 3-50            [-1, 400]                 800\n",
      "|    |    └─SELU: 3-51                   [-1, 400]                 --\n",
      "|    |    └─Linear: 3-52                 [-1, 800]                 320,800\n",
      "|    |    └─BatchNorm1d: 3-53            [-1, 800]                 1,600\n",
      "|    |    └─SELU: 3-54                   [-1, 800]                 --\n",
      "|    └─Sequential: 2-12                  [-1, 800]                 --\n",
      "|    |    └─Linear: 3-55                 [-1, 400]                 320,400\n",
      "|    |    └─BatchNorm1d: 3-56            [-1, 400]                 800\n",
      "|    |    └─SELU: 3-57                   [-1, 400]                 --\n",
      "|    |    └─Linear: 3-58                 [-1, 800]                 320,800\n",
      "|    |    └─BatchNorm1d: 3-59            [-1, 800]                 1,600\n",
      "|    |    └─SELU: 3-60                   [-1, 800]                 --\n",
      "|    └─Sequential: 2-13                  [-1, 800]                 --\n",
      "|    |    └─Linear: 3-61                 [-1, 400]                 320,400\n",
      "|    |    └─BatchNorm1d: 3-62            [-1, 400]                 800\n",
      "|    |    └─SELU: 3-63                   [-1, 400]                 --\n",
      "|    |    └─Linear: 3-64                 [-1, 800]                 320,800\n",
      "|    |    └─BatchNorm1d: 3-65            [-1, 800]                 1,600\n",
      "|    |    └─SELU: 3-66                   [-1, 800]                 --\n",
      "|    └─Sequential: 2-14                  [-1, 800]                 --\n",
      "|    |    └─Linear: 3-67                 [-1, 400]                 320,400\n",
      "|    |    └─BatchNorm1d: 3-68            [-1, 400]                 800\n",
      "|    |    └─SELU: 3-69                   [-1, 400]                 --\n",
      "|    |    └─Linear: 3-70                 [-1, 800]                 320,800\n",
      "|    |    └─BatchNorm1d: 3-71            [-1, 800]                 1,600\n",
      "|    |    └─SELU: 3-72                   [-1, 800]                 --\n",
      "|    └─Sequential: 2-15                  [-1, 800]                 --\n",
      "|    |    └─Linear: 3-73                 [-1, 400]                 320,400\n",
      "|    |    └─BatchNorm1d: 3-74            [-1, 400]                 800\n",
      "|    |    └─SELU: 3-75                   [-1, 400]                 --\n",
      "|    |    └─Linear: 3-76                 [-1, 800]                 320,800\n",
      "|    |    └─BatchNorm1d: 3-77            [-1, 800]                 1,600\n",
      "|    |    └─SELU: 3-78                   [-1, 800]                 --\n",
      "|    └─Sequential: 2-16                  [-1, 800]                 --\n",
      "|    |    └─Linear: 3-79                 [-1, 400]                 320,400\n",
      "|    |    └─BatchNorm1d: 3-80            [-1, 400]                 800\n",
      "|    |    └─SELU: 3-81                   [-1, 400]                 --\n",
      "|    |    └─Linear: 3-82                 [-1, 800]                 320,800\n",
      "|    |    └─BatchNorm1d: 3-83            [-1, 800]                 1,600\n",
      "|    |    └─SELU: 3-84                   [-1, 800]                 --\n",
      "|    └─Sequential: 2-17                  [-1, 800]                 --\n",
      "|    |    └─Linear: 3-85                 [-1, 400]                 320,400\n",
      "|    |    └─BatchNorm1d: 3-86            [-1, 400]                 800\n",
      "|    |    └─SELU: 3-87                   [-1, 400]                 --\n",
      "|    |    └─Linear: 3-88                 [-1, 800]                 320,800\n",
      "|    |    └─BatchNorm1d: 3-89            [-1, 800]                 1,600\n",
      "|    |    └─SELU: 3-90                   [-1, 800]                 --\n",
      "├─Linear: 1-2                            [-1, 5]                   4,005\n",
      "==========================================================================================\n",
      "Total params: 9,717,205\n",
      "Trainable params: 9,717,205\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 19.36\n",
      "==========================================================================================\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.28\n",
      "Params size (MB): 37.07\n",
      "Estimated Total Size (MB): 37.35\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchsummary import summary\n",
    "\n",
    "batch_size = 200\n",
    "input_size = train_dataset[0][0].shape[0]\n",
    "output_size = train_dataset[0][1].shape[0]\n",
    "\n",
    "data_loader_train = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "data_loader_test = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "n_layers = 15\n",
    "n_hidden = 800\n",
    "model = MLP(input_size, output_size, n_layers, n_hidden)\n",
    "\n",
    "lr = 1e-5\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "_ = summary(model, (input_size,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10\n",
      "Train loss: 0.34824 \t\t\t\t\tVal loss: 0.34833\n",
      "Train precision: 4.52e-02 (5.36e-02)                  \tVal precision: 4.52e-02 (5.24e-02)\n",
      "Epoch 20\n",
      "Train loss: 0.34444 \t\t\t\t\tVal loss: 0.34515\n",
      "Train precision: 3.85e-02 (4.97e-02)                  \tVal precision: 3.81e-02 (4.85e-02)\n",
      "Epoch 30\n",
      "Train loss: 0.34174 \t\t\t\t\tVal loss: 0.34215\n",
      "Train precision: 3.38e-02 (4.67e-02)                  \tVal precision: 3.35e-02 (4.55e-02)\n",
      "Epoch 40\n",
      "Train loss: 0.33987 \t\t\t\t\tVal loss: 0.34044\n",
      "Train precision: 3.12e-02 (4.40e-02)                  \tVal precision: 3.11e-02 (4.27e-02)\n",
      "Epoch 50\n",
      "Train loss: 0.33879 \t\t\t\t\tVal loss: 0.33918\n",
      "Train precision: 2.88e-02 (4.31e-02)                  \tVal precision: 2.89e-02 (4.26e-02)\n",
      "Epoch 60\n",
      "Train loss: 0.33828 \t\t\t\t\tVal loss: 0.33940\n",
      "Train precision: 2.80e-02 (4.16e-02)                  \tVal precision: 2.80e-02 (4.16e-02)\n",
      "Epoch 70\n",
      "Train loss: 0.33845 \t\t\t\t\tVal loss: 0.33811\n",
      "Train precision: 2.87e-02 (4.20e-02)                  \tVal precision: 2.88e-02 (4.16e-02)\n",
      "Epoch 80\n",
      "Train loss: 0.33753 \t\t\t\t\tVal loss: 0.33750\n",
      "Train precision: 2.63e-02 (4.06e-02)                  \tVal precision: 2.66e-02 (4.08e-02)\n",
      "Epoch 90\n",
      "Train loss: 0.33731 \t\t\t\t\tVal loss: 0.33809\n",
      "Train precision: 2.53e-02 (4.03e-02)                  \tVal precision: 2.58e-02 (4.04e-02)\n",
      "Epoch 100\n",
      "Train loss: 0.33700 \t\t\t\t\tVal loss: 0.33785\n",
      "Train precision: 2.55e-02 (4.03e-02)                  \tVal precision: 2.58e-02 (4.05e-02)\n",
      "Wall time: 6min 54s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "epochs = 100\n",
    "print_each = 10\n",
    "perfs = train(model, data_loader_train, data_loader_test,\n",
    "              criterion, optimizer, epochs,\n",
    "              print_each=print_each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
